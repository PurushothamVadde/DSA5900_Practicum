{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prudhvi\\Anaconda3\\lib\\site-packages\\requests\\__init__.py:91: RequestsDependencyWarning: urllib3 (1.26.3) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "# !pip install selenium\n",
    "import requests\n",
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "import string\n",
    "import re\n",
    "import pandas as pd\n",
    "import time \n",
    "from selenium import webdriver\n",
    "import json\n",
    "import os\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "  def Customer_Review_Data(Review_div,html_tags):\n",
    "    \n",
    "    # Intializing the customer features\n",
    "    Customer_Friends_count = 0\n",
    "    Customer_Reviews_count = 0\n",
    "    Customer_Photos_count = 0\n",
    "    \n",
    "    # Customer Name\n",
    "    try:\n",
    "        Customer_Name =Review_div.find('span', class_ = html_tags ['C_Name']).text\n",
    "    except:\n",
    "        print(\"error: The HTML string for C_Name in html_tags Json is not Correct\")\n",
    "    \n",
    "    try:\n",
    "        # Customer Data like friends reviews photos\n",
    "        Customer_data = Review_div.find('div', class_ = html_tags['C_Data'])\n",
    "        for i in Customer_data.find_all('div'):\n",
    "            if (i['aria-label'])== 'Friends':\n",
    "                Customer_Friends_count=i.text\n",
    "            if (i['aria-label'])== 'Reviews':\n",
    "                Customer_Reviews_count=i.text\n",
    "            if (i['aria-label'])== 'Photos':\n",
    "                Customer_Photos_count=i.text\n",
    "    except:\n",
    "        print(\"error: The HTML string for C_Data in html_tags Json is not Correct\")\n",
    "    \n",
    "    try:\n",
    "        # Customer Rating For Restaurant\n",
    "        Customer_Rating = (Review_div.find('div',class_= re.compile(html_tags['C_Rating']))['aria-label']).split()[0]\n",
    "    except:\n",
    "        print(\"error: The HTML string for C_Rating in html_tags Json is not Correct\")\n",
    "\n",
    "    try:\n",
    "        # Customer Review\n",
    "        Customer_Review = Review_div.find('p', class_= html_tags['C_Review']).text\n",
    "    except:\n",
    "        print(\"error: The HTML string for C_Review in html_tags Json is not Correct\")\n",
    "       \n",
    "    try:        \n",
    "        # Customer Review Date\n",
    "        Customer_Review_Date = Review_div.find('div', class_ = html_tags['C_R_Date']).text\n",
    "    except:\n",
    "        print(\"error: The HTML string for C_R_Date in html_tags Json is not Correct\")\n",
    "    \n",
    "    try:\n",
    "        # Like Categories\n",
    "        likes_class = Review_div.find('div',class_= html_tags['Like_class'])\n",
    "\n",
    "        Temp_emoji=[]\n",
    "        for span in likes_class.find_all('span',class_=  html_tags['Like_Category']):\n",
    "            if (len((span.text).split())>1):\n",
    "                Temp_emoji.append((span.text).split()[1])\n",
    "            else:\n",
    "                Temp_emoji.append(0)\n",
    "\n",
    "        Customer_Review_Useful = Temp_emoji[0]\n",
    "        Customer_Review_Funny = Temp_emoji[1]\n",
    "        Customer_Review_Cool = Temp_emoji[2]\n",
    "    except:\n",
    "        print(\"error: The HTML string for Like_class/Like_Category in html_tags Json is not Correct\")\n",
    "    \n",
    "    #######################################################################################################\n",
    "    # Customer Uploaded photos\n",
    "    if (Review_div.find('span',class_= html_tags['C_R_Photos'])):\n",
    "        Customer_Review_Uploaded_Photos=(Review_div.find('span',class_=html_tags['C_R_Photos']).text.split()[0])\n",
    "    else:\n",
    "        Customer_Review_Uploaded_Photos = 0\n",
    "\n",
    "    # Is Customer in Elite Group\n",
    "    if Review_div.find('p', class_ = html_tags['C_Elite']):\n",
    "        Customer_Elite = 'Yes'\n",
    "        Customer_Elite_Year = (Review_div.find('p', class_ = html_tags['C_Elite'])).text.split()[1]\n",
    "    else:\n",
    "        Customer_Elite = 'No'\n",
    "        Customer_Elite_Year ='0'     \n",
    "        \n",
    "    # Business Response class\n",
    "    if Review_div.find('div',class_=html_tags['B_R_Class']):\n",
    "        Business_response_class=Review_div.find('div',class_=html_tags['B_R_Class'])\n",
    "        if Business_response_class.find('div',class_= html_tags['B_R_Check']):       \n",
    "            # Business Response by\n",
    "            Business_response_By = (Business_response_class.find('p', class_= html_tags['B_R_by'])).text\n",
    "            # Business Response date\n",
    "            Business_response_Date = (Business_response_class.find('div', class_= html_tags['B_R_Date'])).text\n",
    "            # Business  Response\n",
    "            if Business_response_class.find('p', class_= html_tags['B_Response']):\n",
    "                Business_Response_for_Review =(Business_response_class.find('p', class_=html_tags['B_Response'])).text\n",
    "                Business_Response = '1'\n",
    "            else:\n",
    "                Business_Response_for_Review = 'Null'\n",
    "                Business_Response = '0'\n",
    "        else:\n",
    "            Business_response_By ='Null'\n",
    "            Business_response_Date= 'Null'\n",
    "            Business_Response_for_Review ='Null'\n",
    "            Business_Response = '0'\n",
    "    else:\n",
    "        Business_response_By ='Null'\n",
    "        Business_response_Date= 'Null'\n",
    "        Business_Response_for_Review ='Null'\n",
    "        Business_Response = '0'\n",
    "        \n",
    "    ######################################################################################################\n",
    "    Customer_Review_Details =[Customer_Name, \n",
    "                              Customer_Friends_count,\n",
    "                              Customer_Reviews_count,\n",
    "                              Customer_Photos_count, \n",
    "                              Customer_Elite,\n",
    "                              Customer_Elite_Year, \n",
    "                              Customer_Rating, \n",
    "                              Customer_Review, \n",
    "                              Customer_Review_Date, \n",
    "                              Customer_Review_Uploaded_Photos,\n",
    "                              Customer_Review_Useful, \n",
    "                              Customer_Review_Funny, \n",
    "                              Customer_Review_Cool, \n",
    "                              Business_response_By, \n",
    "                              Business_response_Date, \n",
    "                              Business_Response_for_Review,\n",
    "                              Business_Response]\n",
    "                             \n",
    "    return Customer_Review_Details\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Customer_Data(link,html_tags,Business_Details,Data_Frame):\n",
    "    \n",
    "    for i in range(0,int(Business_Details[2]),20):      \n",
    "#         print(i)\n",
    "        # initiating the webdriver. Parameter includes the path of the webdriver. \n",
    "        driver = webdriver.Chrome('C:/Users/Prudhvi/Anaconda3/chromedriver') \n",
    "        driver.get(link+'?start='+str(i)) \n",
    "        # this is just to ensure that the page is loaded \n",
    "        time.sleep(2)  \n",
    "        html = driver.page_source \n",
    "        driver.quit()\n",
    "        # Now, we could simply apply bs4 to html variable \n",
    "        soup = BeautifulSoup(html, \"html.parser\")\n",
    "        # Getting the Customer Reviews Div\n",
    "        \n",
    "        try:\n",
    "            Customer_Reviews_div = soup.find_all('div', class_=html_tags['Reviews_Div'])\n",
    "        except:\n",
    "            print(\"error: The HTML string for Reviews_Div in html_tags Json is not Correct\")\n",
    "            \n",
    "        # creating  a Data frame to save data\n",
    "        Data_Frame =pd.DataFrame(columns= [ 'Business_Name',\n",
    "                                            'Business_Address',\n",
    "                                            'Business_ReviewCount',\n",
    "                                            'Business_Rating',\n",
    "                                            'Business_Photos_Count',\n",
    "                                            'Business_Timings',\n",
    "                                            'Business_Claim_status',\n",
    "#                                             'Business_Response_Time',\n",
    "#                                             'Business_Response_Rate',\n",
    "                                            'Customer_Name', \n",
    "                                            'Customer_Friends_count',\n",
    "                                            'Customer_Reviews_count',\n",
    "                                            'Customer_Photos_count', \n",
    "                                            'Customer_Elite',\n",
    "                                            'Customer_Elite_Year', \n",
    "                                            'Customer_Rating', \n",
    "                                            'Customer_Review', \n",
    "                                            'Customer_Review_Date', \n",
    "                                            'Customer_Review_Uploaded_Photos',\n",
    "                                            'Customer_Review_Useful', \n",
    "                                            'Customer_Review_Funny', \n",
    "                                            'Customer_Review_Cool', \n",
    "                                            'Business_response_By', \n",
    "                                            'Business_response_Date', \n",
    "                                            'Business_Response_for_Review',\n",
    "                                            'Business_Response'])            \n",
    "\n",
    "        for div in Customer_Reviews_div :\n",
    "            # calling Customer Review Data Function\n",
    "            Customer_Review_Details = Customer_Review_Data(div,html_tags)\n",
    "            # writing the Business and Customer Review details to a Data frame \n",
    "            data =[{'Business_Name':Business_Details[0],\n",
    "                        'Business_Address':Business_Details[1],\n",
    "                        'Business_ReviewCount':Business_Details[2],\n",
    "                        'Business_Rating':Business_Details[3],\n",
    "                        'Business_Photos_Count':Business_Details[4],\n",
    "                        'Business_Timings':Business_Details[5],\n",
    "                        'Business_Claim_status':Business_Details[6],\n",
    "#                         'Business_Response_Time':Business_Details[7],\n",
    "#                         'Business_Response_Rate':Business_Details[8],\n",
    "                        'Customer_Name':Customer_Review_Details[0], \n",
    "                        'Customer_Friends_count':Customer_Review_Details[1],\n",
    "                        'Customer_Reviews_count':Customer_Review_Details[2],\n",
    "                        'Customer_Photos_count':Customer_Review_Details[3], \n",
    "                        'Customer_Elite':Customer_Review_Details[4],\n",
    "                        'Customer_Elite_Year':Customer_Review_Details[5], \n",
    "                        'Customer_Rating':Customer_Review_Details[6], \n",
    "                        'Customer_Review':Customer_Review_Details[7], \n",
    "                        'Customer_Review_Date':Customer_Review_Details[8], \n",
    "                        'Customer_Review_Uploaded_Photos':Customer_Review_Details[9],\n",
    "                        'Customer_Review_Useful':Customer_Review_Details[10], \n",
    "                        'Customer_Review_Funny':Customer_Review_Details[11], \n",
    "                        'Customer_Review_Cool':Customer_Review_Details[12], \n",
    "                        'Business_response_By':Customer_Review_Details[13], \n",
    "                        'Business_response_Date':Customer_Review_Details[14], \n",
    "                        'Business_Response_for_Review':Customer_Review_Details[15],\n",
    "                        'Business_Response':Customer_Review_Details[16]}]\n",
    "            \n",
    "            # appending data for each review div \n",
    "            Data_Frame = Data_Frame.append(data, ignore_index=True,sort=False)\n",
    "            \n",
    "        Data_Frame.to_csv('../Data_Business_Reviews/Yelp_Business_Reviews_Seattle_Painters.csv', mode='a', header=False) \n",
    "        \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Business_Data(soup, html_tags, link, Data_Frame):\n",
    "    try:\n",
    "        # Reading the Business class from soup\n",
    "        Business_class = soup.find('div', class_=html_tags['B_class'])\n",
    "    except:\n",
    "        print(\"error: The HTML string for B_class in html_tags Json is not Correct\")\n",
    "    try:\n",
    "        # Business Name\n",
    "        Business_Name = Business_class.find('h1', class_=html_tags['B_Name']).text\n",
    "    except:\n",
    "        print(\"error: The HTML string for B_Name in html_tags Json is not Correct\")\n",
    "\n",
    "    try:\n",
    "        # Business Reviews Count\n",
    "        Business_ReviewCount = (Business_class.find('span', class_=html_tags['B_Review']).text).split()[0]\n",
    "    except:\n",
    "        print(\"error: The HTML string for B_Review in html_tags Json is not Correct\")\n",
    "    try:\n",
    "        # Business Rating\n",
    "        Business_Rating = (Business_class.find('div', class_=re.compile(html_tags['B_Rating']))['aria-label']).split()[0]\n",
    "    except:\n",
    "        print(\"error: The HTML string for B_Rating in html_tags Json is not Correct\")\n",
    "\n",
    "    ####################################################################################################\n",
    "\n",
    "    if soup.find_all(html_tags['B_Address']):\n",
    "        # Business Address\n",
    "        Business_Address = ''\n",
    "        for class_ in soup.find_all(html_tags['B_Address']):\n",
    "            Business_Address += class_.text\n",
    "    else:\n",
    "        Business_Address = 'Null'\n",
    "\n",
    "    if (Business_class.find('span', class_=html_tags['B_photos'])):\n",
    "        # Business  Photos Count\n",
    "        Business_Photos_Count = (Business_class.find('span', class_=html_tags['B_photos']).text).split()[1]\n",
    "    else:\n",
    "        Business_Photos_Count = 'Null'\n",
    "\n",
    "    if Business_class.find('span', class_=html_tags['B_Claim']):\n",
    "        # Business Claimed Status\n",
    "        Business_Claim_status = (Business_class.find('span', class_=html_tags['B_Claim']).text).strip()\n",
    "    else:\n",
    "        Business_Claim_status = 'Null'\n",
    "\n",
    "    # Business Timings\n",
    "    if Business_class.find('span', class_=html_tags['B_Timings']):\n",
    "        Business_Timings = Business_class.find('span', class_=html_tags['B_Timings']).text\n",
    "    else:\n",
    "        Business_Timings = 'Null'\n",
    "\n",
    "    # Business Response Rate and Time\n",
    "#     if soup.find('div', class_=html_tags['B_Response_Class']):\n",
    "#         Delivery_class = soup.find('div', class_=html_tags['B_Response_Class'])\n",
    "#         if (Delivery_class.find('div', class_=html_tags['B_Response_Time'])):\n",
    "#             temp_time = Delivery_class.find('div', class_=html_tags['B_Response_Time'])\n",
    "#             Business_Response_Time = (temp_time.find('p', class_=html_tags['B_Response_text_class']).text)\n",
    "#         else:\n",
    "#             Business_Response_Time = 'Null'\n",
    "#         if (Delivery_class.find('div', class_=html_tags['B_Response_Rate'])):\n",
    "#             temp_rate=  Delivery_class.find('div', class_=html_tags['B_Response_Rate'])\n",
    "#             Business_Response_Rate = (temp_rate.find('p', class_=html_tags['B_Response_text_class']).text)\n",
    "#         else:\n",
    "#             Business_Response_Rate = 'Null'\n",
    "#     else:\n",
    "#         Business_Response_Time = 'Null'\n",
    "#         Business_Response_Rate = 'Null'\n",
    "\n",
    "#     print(Business_Response_Time)\n",
    "   \n",
    "\n",
    "        ###################################################################################################\n",
    "    Business_Details = [Business_Name,\n",
    "                        Business_Address,\n",
    "                        Business_ReviewCount,\n",
    "                        Business_Rating,\n",
    "                        Business_Photos_Count,\n",
    "                        Business_Timings,\n",
    "                        Business_Claim_status,\n",
    "#                         Business_Response_Time,\n",
    "#                         Business_Response_Rate\n",
    "                       ]\n",
    "\n",
    "#     print(Business_Details)\n",
    "    # Iterating each page of business to get reviews and customer html_tags\n",
    "    Customer_Data(link, html_tags, Business_Details, Data_Frame)\n",
    "\n",
    "    return Business_Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "703\n",
      "645 https://www.yelp.com/biz/sears-appliance-repair-tukwila?osq=HVAC\n",
      "No Reviews\n",
      "646 https://www.yelp.com/biz/heat-flow-mechanical-auburn?osq=HVAC\n",
      "647 https://www.yelp.com/biz/all-american-air-systems-bonney-lake?osq=HVAC\n",
      "No Reviews\n",
      "648 https://www.yelp.com/biz/rem-services-federal-way?osq=HVAC\n",
      "649 https://www.yelp.com/biz/allreds-plumbing-and-radiant-tukwila-2?osq=HVAC\n",
      "650 https://www.yelp.com/biz/dicks-heating-and-ac-sumner?osq=HVAC\n",
      "No Reviews\n",
      "651 https://www.yelp.com/biz/home-services-at-the-home-depot-shoreline-2?osq=HVAC\n",
      "652 https://www.yelp.com/biz/forest-ridge-plumbing-lynnwood-8?osq=HVAC\n",
      "653 https://www.yelp.com/biz/pacwest-services-everett-2?osq=HVAC\n",
      "654 https://www.yelp.com/biz/asap-water-heating-everett?osq=HVAC\n",
      "655 https://www.yelp.com/biz/service-max-arlington?osq=HVAC\n",
      "656 https://www.yelp.com/biz/green-heat-service-seattle?osq=HVAC\n",
      "657 https://www.yelp.com/biz/go-green-heating-and-air-conditioning-seattle?osq=HVAC\n",
      "658 https://www.yelp.com/biz/innovative-thermal-solutions-inc-edgewood?osq=HVAC\n",
      "659 https://www.yelp.com/biz/valley-furnace-puyallup?osq=HVAC\n",
      "No Reviews\n",
      "660 https://www.yelp.com/biz/summit-heating-and-air-conditioning-tacoma?osq=HVAC\n",
      "661 https://www.yelp.com/biz/makro-heating-kent?osq=HVAC\n",
      "No Reviews\n",
      "662 https://www.yelp.com/biz/eco-air-nw-federal-way-2?osq=HVAC\n",
      "663 https://www.yelp.com/biz/piece-of-mind-home-comfort-puyallup?osq=HVAC\n",
      "664 https://www.yelp.com/biz/tacoma-hvac-tacoma-2?osq=HVAC\n",
      "665 https://www.yelp.com/biz/puyallup-heating-and-air-conditioning-puyallup?osq=HVAC\n",
      "666 https://www.yelp.com/biz/all-seasons-lakewood?osq=HVAC\n",
      "667 https://www.yelp.com/biz/air-anderson-port-orchard-2?osq=HVAC\n",
      "668 https://www.yelp.com/biz/absolute-heating-and-cooling-auburn-2?osq=HVAC\n",
      "669 https://www.yelp.com/biz/magic-clean-air-duct-cleaning-service-lake-tapps?osq=HVAC\n",
      "No Reviews\n",
      "670 https://www.yelp.com/biz/ats-automation-renton-2?osq=HVAC\n",
      "671 https://www.yelp.com/biz/sears-home-improvement-seattle-3?osq=HVAC\n",
      "No Reviews\n",
      "672 https://www.yelp.com/biz/nine-mercer-island-4?osq=HVAC\n",
      "673 https://www.yelp.com/biz/the-fireplace-and-chimney-service-burien?osq=HVAC\n",
      "No Reviews\n",
      "674 https://www.yelp.com/biz/hc-heating-and-cooling-bainbridge-island-2?osq=HVAC\n",
      "675 https://www.yelp.com/biz/switch-electric-home-energy-lake-stevens?osq=HVAC\n",
      "No Reviews\n",
      "676 https://www.yelp.com/biz/goodman-heaters-repair-pro-seattle?osq=HVAC\n",
      "No Reviews\n",
      "677 https://www.yelp.com/biz/south-county-heating-inc-kent-2?osq=HVAC\n",
      "678 https://www.yelp.com/biz/aqualine-plumbing-electrical-and-heating-kent-2?osq=HVAC\n",
      "No Reviews\n",
      "679 https://www.yelp.com/biz/universal-refrigeration-auburn?osq=HVAC\n",
      "680 https://www.yelp.com/biz/draft-air-mechanical-tumwater?osq=HVAC\n",
      "681 https://www.yelp.com/biz/forest-song-heating-and-air-conditioning-covington-2?osq=HVAC\n",
      "682 https://www.yelp.com/biz/mark-wiseman-appliance-service-seattle-2?osq=HVAC\n",
      "683 https://www.yelp.com/biz/infinity-heating-and-air-graham-3?osq=HVAC\n",
      "684 https://www.yelp.com/biz/seattle-mechanical-auburn?osq=HVAC\n",
      "685 https://www.yelp.com/biz/bronze-heating-and-air-edgewood?osq=HVAC\n",
      "686 https://www.yelp.com/biz/city-energy-systems-auburn?osq=HVAC\n",
      "687 https://www.yelp.com/biz/kyles-heating-renton?osq=HVAC\n",
      "No Reviews\n",
      "688 https://www.yelp.com/biz/gensco-auburn?osq=HVAC\n",
      "No Reviews\n",
      "689 https://www.yelp.com/biz/discount-heating-and-air-auburn?osq=HVAC\n",
      "690 https://www.yelp.com/biz/aqualine-plumbing-electrical-and-heating-auburn-4?osq=HVAC\n",
      "691 https://www.yelp.com/biz/hinze-heating-and-cooling-spanaway?osq=HVAC\n",
      "692 https://www.yelp.com/biz/gregs-manufactured-mobile-home-heating-and-a-c-spanaway?osq=HVAC\n",
      "693 https://www.yelp.com/biz/federal-way-furnace-edgewood-3?osq=HVAC\n",
      "694 https://www.yelp.com/biz/csi-hvac-tacoma?osq=HVAC\n",
      "No Reviews\n",
      "695 https://www.yelp.com/biz/auburn-plumbing-and-heating-auburn-2?osq=HVAC\n",
      "696 https://www.yelp.com/biz/superior-air-services-tacoma?osq=HVAC\n",
      "697 https://www.yelp.com/biz/expert-air-control-puyallup-4?osq=HVAC\n",
      "No Reviews\n",
      "698 https://www.yelp.com/biz/competitive-heating-and-cooling-federal-way?osq=HVAC\n",
      "699 https://www.yelp.com/biz/mitchel-plumbing-tacoma-2?osq=HVAC\n",
      "700 https://www.yelp.com/biz/dr-cool-dr-heat-sumner-2?osq=HVAC\n",
      "701 https://www.yelp.com/biz/evergreen-pure-air-seattle?osq=HVAC\n",
      "No Reviews\n",
      "702 https://www.yelp.com/biz/nortech-heating-and-cooling-seattle?osq=HVAC\n"
     ]
    }
   ],
   "source": [
    "if __name__== '__main__':\n",
    "    \n",
    "    # Loading the HTML tags from Data json file\n",
    "    with open('html_tags.json') as f:\n",
    "        html_tags = json.load(f)\n",
    "    \n",
    "    \n",
    "    # Reading the business links from the CSV and storing into list\n",
    "    df = pd.read_csv('../Data_Business_URL_Links/Business_links_Painters_Seattle.csv')\n",
    "    \n",
    "    Business_links = df['Business_links']\n",
    "    print(len(Business_links))\n",
    "    Business_links = Business_links.tolist()\n",
    "    # Business_links\n",
    "    # creating  a Data frame to save data\n",
    "    Data_Frame =pd.DataFrame(columns= [ 'Business_Name', 'Business_Address', 'Business_ReviewCount', 'Business_Rating',\n",
    "                                        'Business_Photos_Count', 'Business_Timings', 'Business_Claim_status','Customer_Name', \n",
    "                                        'Customer_Friends_count', 'Customer_Reviews_count', 'Customer_Photos_count', 'Customer_Elite',\n",
    "                                        'Customer_Elite_Year', 'Customer_Rating', 'Customer_Review', 'Customer_Review_Date', \n",
    "                                        'Customer_Review_Uploaded_Photos', 'Customer_Review_Useful', 'Customer_Review_Funny', \n",
    "                                        'Customer_Review_Cool', 'Business_response_By', 'Business_response_Date', \n",
    "                                        'Business_Response_for_Review', 'Business_Response']) \n",
    "    \n",
    "    # Creating a CSV file with headers to save data\n",
    "    Data_Frame.to_csv('../Data_Business_Reviews/Yelp_Business_Reviews_Seattle_Painters.csv', header=True)\n",
    "    \n",
    "    \n",
    "#     try:\n",
    "        \n",
    "    for i in range(645,len(Business_links),1):\n",
    "        \n",
    "        link = Business_links[i]      \n",
    "        driver = webdriver.Chrome('C:/Users/Prudhvi/Anaconda3/chromedriver')\n",
    "        driver.get(link)\n",
    "        # this is just to ensure that the page is loaded\n",
    "        time.sleep(2)\n",
    "        html = driver.page_source\n",
    "        driver.quit()\n",
    "        # Now, we could simply apply bs4 to html variable\n",
    "        soup = BeautifulSoup(html, \"html.parser\")\n",
    "        Business_class = soup.find('div', class_=html_tags['B_class'])       \n",
    "#         Reviwes_check =((Business_class.find('span', class_=html_tags['B_Review']).text).split()[0]).isnumeric()\n",
    "#         print((Business_class.find('span', class_=html_tags['B_Review']).text).split()[0])\n",
    "        \n",
    "        Reviwes_check = soup.find_all('div', class_=html_tags['Reviews_Div'])\n",
    "        if Reviwes_check:\n",
    "            print(i, link)  \n",
    "            Business_Data(soup,html_tags,link,Data_Frame)\n",
    "        else:\n",
    "            print('No Reviews')\n",
    "            print(i, link)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update the path of reviews data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of Data frame with Duplicate URL : 13317\n",
      "The length of DataFrame after droping the Duplicates : 13317\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "def Remove_Duplicates(DataFrame, path):\n",
    "    for fname in glob.glob(path):\n",
    "        df = pd.read_csv(fname)\n",
    "        DataFrame = DataFrame.append(df, ignore_index=True)\n",
    "\n",
    "    # Dropping the Duplicate values:\n",
    "    print(\"The length of Data frame with Duplicate URL :\",len(DataFrame))\n",
    "    print('The length of DataFrame after droping the Duplicates :', len(DataFrame))\n",
    "\n",
    "    DataFrame.to_csv('../yelp/ReviewsData/Yelp_Business_Reviews_Seattle_HVAC.csv')\n",
    "\n",
    "\n",
    "    return 0\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    DataFrame = pd.DataFrame()\n",
    "    path = '../yelp/ReviewsData/Yelp_Business_Reviews_Seattle_HVAC_*.csv'\n",
    "\n",
    "    Remove_Duplicates(DataFrame, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
