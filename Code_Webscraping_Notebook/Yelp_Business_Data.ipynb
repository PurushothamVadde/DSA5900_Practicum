{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\prudhvi\\anaconda3\\lib\\site-packages (3.141.0)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\prudhvi\\anaconda3\\lib\\site-packages (from selenium) (1.25.11)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium\n",
    "import requests\n",
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "import string\n",
    "import re\n",
    "import pandas as pd\n",
    "import time \n",
    "from selenium import webdriver\n",
    "import json\n",
    "import os\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract the Customer and customer reviews data\n",
    "def Customer_Review_Data(Review_div,html_tags):\n",
    "    \n",
    "    # Intializing the customer features\n",
    "    Customer_Friends_count = 0\n",
    "    Customer_Reviews_count = 0\n",
    "    Customer_Photos_count =  0\n",
    "    \n",
    "    # Extracting Customer Name\n",
    "    try:\n",
    "        Customer_Name =Review_div.find('span', class_ = html_tags ['C_Name']).text\n",
    "    except:\n",
    "        print(\"error: The HTML string for C_Name in html_tags Json is not Correct\")\n",
    "    \n",
    "    try:\n",
    "        # Extracting Customer Data like friends reviews photos\n",
    "        Customer_data = Review_div.find('div', class_ = html_tags['C_Data'])\n",
    "        for i in Customer_data.find_all('div'):\n",
    "            if (i['aria-label'])== 'Friends':\n",
    "                Customer_Friends_count=i.text\n",
    "            if (i['aria-label'])== 'Reviews':\n",
    "                Customer_Reviews_count=i.text\n",
    "            if (i['aria-label'])== 'Photos':\n",
    "                Customer_Photos_count=i.text\n",
    "    except:\n",
    "        print(\"error: The HTML string for C_Data in html_tags Json is not Correct\")\n",
    "    \n",
    "    try:\n",
    "        #Extracting Customer Rating For Restaurant\n",
    "        Customer_Rating = (Review_div.find('div',class_= re.compile(html_tags['C_Rating']))['aria-label']).split()[0]\n",
    "    except:\n",
    "        print(\"error: The HTML string for C_Rating in html_tags Json is not Correct\")\n",
    "\n",
    "    try:\n",
    "        #Extracting Customer Review\n",
    "        Customer_Review = Review_div.find('p', class_= html_tags['C_Review']).text\n",
    "    except:\n",
    "        print(\"error: The HTML string for C_Review in html_tags Json is not Correct\")\n",
    "       \n",
    "    try:        \n",
    "        #Extracting Customer Review Date\n",
    "        Customer_Review_Date = Review_div.find('div', class_ = html_tags['C_R_Date']).text\n",
    "    except:\n",
    "        print(\"error: The HTML string for C_R_Date in html_tags Json is not Correct\")\n",
    "    \n",
    "    try:\n",
    "        #Extracting Like Categories\n",
    "        likes_class = Review_div.find('div',class_= html_tags['Like_class'])\n",
    "\n",
    "        Temp_emoji=[]\n",
    "        for span in likes_class.find_all('span',class_=  html_tags['Like_Category']):\n",
    "            if (len((span.text).split())>1):\n",
    "                Temp_emoji.append((span.text).split()[1])\n",
    "            else:\n",
    "                Temp_emoji.append(0)\n",
    "\n",
    "        Customer_Review_Useful = Temp_emoji[0]\n",
    "        Customer_Review_Funny = Temp_emoji[1]\n",
    "        Customer_Review_Cool = Temp_emoji[2]\n",
    "    except:\n",
    "        print(\"error: The HTML string for Like_class/Like_Category in html_tags Json is not Correct\")\n",
    "    \n",
    "    #######################################################################################################\n",
    "    #Extracting Customer Uploaded photos\n",
    "    if (Review_div.find('span',class_= html_tags['C_R_Photos'])):\n",
    "        Customer_Review_Uploaded_Photos=(Review_div.find('span',class_=html_tags['C_R_Photos']).text.split()[0])\n",
    "    else:\n",
    "        Customer_Review_Uploaded_Photos = 0\n",
    "\n",
    "    #Extracting Is Customer in Elite Group\n",
    "    if Review_div.find('p', class_ = html_tags['C_Elite']):\n",
    "        Customer_Elite = 'Yes'\n",
    "        Customer_Elite_Year = (Review_div.find('p', class_ = html_tags['C_Elite'])).text.split()[1]\n",
    "    else:\n",
    "        Customer_Elite = 'No'\n",
    "        Customer_Elite_Year ='0'     \n",
    "        \n",
    "    #Extracting Business Response class\n",
    "    if Review_div.find('div',class_=html_tags['B_R_Class']):\n",
    "        Business_response_class=Review_div.find('div',class_=html_tags['B_R_Class'])\n",
    "        if Business_response_class.find('div',class_= html_tags['B_R_Check']):       \n",
    "            #Extracting Business Response by\n",
    "            Business_response_By = (Business_response_class.find('p', class_= html_tags['B_R_by'])).text\n",
    "            #Extracting Business Response date\n",
    "            Business_response_Date = (Business_response_class.find('div', class_= html_tags['B_R_Date'])).text\n",
    "            #Extracting Business  Response\n",
    "            if Business_response_class.find('p', class_= html_tags['B_Response']):\n",
    "                Business_Response_for_Review =(Business_response_class.find('p', class_=html_tags['B_Response'])).text\n",
    "                Business_Response = '1'\n",
    "            else:\n",
    "                Business_Response_for_Review = 'Null'\n",
    "                Business_Response = '0'\n",
    "        else:\n",
    "            Business_response_By ='Null'\n",
    "            Business_response_Date= 'Null'\n",
    "            Business_Response_for_Review ='Null'\n",
    "            Business_Response = '0'\n",
    "    else:\n",
    "        Business_response_By ='Null'\n",
    "        Business_response_Date= 'Null'\n",
    "        Business_Response_for_Review ='Null'\n",
    "        Business_Response = '0'\n",
    "        \n",
    "    ######################################################################################################\n",
    "    Customer_Review_Details =[Customer_Name, \n",
    "                              Customer_Friends_count,\n",
    "                              Customer_Reviews_count,\n",
    "                              Customer_Photos_count, \n",
    "                              Customer_Elite,\n",
    "                              Customer_Elite_Year, \n",
    "                              Customer_Rating, \n",
    "                              Customer_Review, \n",
    "                              Customer_Review_Date, \n",
    "                              Customer_Review_Uploaded_Photos,\n",
    "                              Customer_Review_Useful, \n",
    "                              Customer_Review_Funny, \n",
    "                              Customer_Review_Cool, \n",
    "                              Business_response_By, \n",
    "                              Business_response_Date, \n",
    "                              Business_Response_for_Review,\n",
    "                              Business_Response]\n",
    "                             \n",
    "    return Customer_Review_Details\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Customer_Data(link,html_tags,Business_Details,Data_Frame, city, category):\n",
    "    \n",
    "    # iterating through the each page with business reviews for business each page using the incrementer 10 \n",
    "    # each page will have 10 reviews\n",
    "    \n",
    "    for i in range(0,int(Business_Details[2]),10):      \n",
    "        # initiating the webdriver. Parameter includes the path of the webdriver. \n",
    "        driver = webdriver.Chrome('../chromedriver/chromedriver.exe') \n",
    "        if('?osq') in link:\n",
    "            current_url = link+'&start='+str(i)\n",
    "        else: \n",
    "            current_url = link+'?start='+str(i)\n",
    "            \n",
    "        print(current_url)\n",
    "        driver.get(current_url) \n",
    "        # this is just to ensure that the page is loaded \n",
    "        time.sleep(2)  \n",
    "        html = driver.page_source \n",
    "        driver.quit()\n",
    "        # Now, we could simply apply bs4 to html variable \n",
    "        soup = BeautifulSoup(html, \"html.parser\")\n",
    "        \n",
    "        # Getting the Customer Reviews Div with all reviews in a page\n",
    "        try:\n",
    "            Customer_Reviews_div = soup.find_all('div', class_=html_tags['Reviews_Div'])\n",
    "        except:\n",
    "            print(\"error: The HTML string for Reviews_Div in html_tags Json is not Correct\")\n",
    "            \n",
    "        # creating  a Data frame to save data\n",
    "        Data_Frame =pd.DataFrame(columns= [ 'Business_Name',\n",
    "                                            'Business_Address',\n",
    "                                            'Business_ReviewCount',\n",
    "                                            'Business_Rating',\n",
    "                                            'Business_Photos_Count',\n",
    "                                            'Business_Timings',\n",
    "                                            'Business_Claim_status',\n",
    "                                            'Business_URL',\n",
    "                                            'Customer_Name', \n",
    "                                            'Customer_Friends_count',\n",
    "                                            'Customer_Reviews_count',\n",
    "                                            'Customer_Photos_count', \n",
    "                                            'Customer_Elite',\n",
    "                                            'Customer_Elite_Year', \n",
    "                                            'Customer_Rating', \n",
    "                                            'Customer_Review', \n",
    "                                            'Customer_Review_Date', \n",
    "                                            'Customer_Review_Uploaded_Photos',\n",
    "                                            'Customer_Review_Useful', \n",
    "                                            'Customer_Review_Funny', \n",
    "                                            'Customer_Review_Cool', \n",
    "                                            'Business_response_By', \n",
    "                                            'Business_response_Date', \n",
    "                                            'Business_Response_for_Review',\n",
    "                                            'Business_Response'])            \n",
    "        \n",
    "        # iterating through the each review and extracting the customer details \n",
    "        for div in Customer_Reviews_div :\n",
    "            \n",
    "            # calling Customer Review Data Function\n",
    "            Customer_Review_Details = Customer_Review_Data(div,html_tags)\n",
    "            \n",
    "            \n",
    "            # writing the Business and Customer Review details to a Data frame \n",
    "            data =[{'Business_Name':Business_Details[0],\n",
    "                        'Business_Address':Business_Details[1],\n",
    "                        'Business_ReviewCount':Business_Details[2],\n",
    "                        'Business_Rating':Business_Details[3],\n",
    "                        'Business_Photos_Count':Business_Details[4],\n",
    "                        'Business_Timings':Business_Details[5],\n",
    "                        'Business_Claim_status':Business_Details[6],\n",
    "                        'Business_URL' : Business_Details[7],\n",
    "                        'Customer_Name':Customer_Review_Details[0], \n",
    "                        'Customer_Friends_count':Customer_Review_Details[1],\n",
    "                        'Customer_Reviews_count':Customer_Review_Details[2],\n",
    "                        'Customer_Photos_count':Customer_Review_Details[3], \n",
    "                        'Customer_Elite':Customer_Review_Details[4],\n",
    "                        'Customer_Elite_Year':Customer_Review_Details[5], \n",
    "                        'Customer_Rating':Customer_Review_Details[6], \n",
    "                        'Customer_Review':Customer_Review_Details[7], \n",
    "                        'Customer_Review_Date':Customer_Review_Details[8], \n",
    "                        'Customer_Review_Uploaded_Photos':Customer_Review_Details[9],\n",
    "                        'Customer_Review_Useful':Customer_Review_Details[10], \n",
    "                        'Customer_Review_Funny':Customer_Review_Details[11], \n",
    "                        'Customer_Review_Cool':Customer_Review_Details[12], \n",
    "                        'Business_response_By':Customer_Review_Details[13], \n",
    "                        'Business_response_Date':Customer_Review_Details[14], \n",
    "                        'Business_Response_for_Review':Customer_Review_Details[15],\n",
    "                        'Business_Response':Customer_Review_Details[16]}]\n",
    "\n",
    "            # appending data for each review div \n",
    "            Data_Frame = Data_Frame.append(data, ignore_index=True,sort=False)\n",
    "        \n",
    "        # appending the reviews for each business\n",
    "        Data_Frame.to_csv('../Data_Business_Reviews/Yelp_Business_Reviews_{0}_{1}.csv'.format(city, category), mode='a', header=False) \n",
    "        \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to extract the business data\n",
    "def Business_Data(soup, html_tags, link, Data_Frame, city, category):\n",
    "    try:\n",
    "        # Extracting the div element with business details and storing into business class\n",
    "        Business_class = soup.find('div', class_=html_tags['B_class'])\n",
    "    except:\n",
    "        print(\"error: The HTML string for B_class in html_tags Json is not Correct\")\n",
    "    try:\n",
    "        #extracting Business Name\n",
    "        Business_Name = Business_class.find('h1', class_=html_tags['B_Name']).text\n",
    "    except:\n",
    "        print(\"error: The HTML string for B_Name in html_tags Json is not Correct\")\n",
    "\n",
    "    try:\n",
    "        #extracting Business Reviews Count\n",
    "        Business_ReviewCount = (Business_class.find('span', class_=html_tags['B_Review']).text).split()[0]\n",
    "    except:\n",
    "        print(\"error: The HTML string for B_Review in html_tags Json is not Correct\")\n",
    "    try:\n",
    "        #extracting Business Rating\n",
    "        Business_Rating = (Business_class.find('div', class_=re.compile(html_tags['B_Rating']))['aria-label']).split()[0]\n",
    "    except:\n",
    "        print(\"error: The HTML string for B_Rating in html_tags Json is not Correct\")\n",
    "\n",
    "    ####################################################################################################\n",
    "    # Extracting Business Address    \n",
    "    if soup.find_all(html_tags['B_Address']):\n",
    "        Business_Address = ''\n",
    "        for class_ in soup.find_all(html_tags['B_Address']):\n",
    "            Business_Address += class_.text\n",
    "    else:\n",
    "        Business_Address = 'Null'\n",
    "    \n",
    "    # Business  Photos Count\n",
    "    if (Business_class.find('span', class_=html_tags['B_photos'])):     \n",
    "        Business_Photos_Count = (Business_class.find('span', class_=html_tags['B_photos']).text).split()[1]\n",
    "    else:\n",
    "        Business_Photos_Count = 'Null'\n",
    "\n",
    "    # Business Claimed Status \n",
    "    if Business_class.find('span', class_=html_tags['B_Claim']):       \n",
    "        Business_Claim_status = (Business_class.find('span', class_=html_tags['B_Claim']).text).strip()\n",
    "    else:\n",
    "        Business_Claim_status = 'Null'\n",
    "\n",
    "    # Business Timings\n",
    "    if Business_class.find('span', class_=html_tags['B_Timings']):\n",
    "        Business_Timings = Business_class.find('span', class_=html_tags['B_Timings']).text\n",
    "    else:\n",
    "        Business_Timings = 'Null'   \n",
    "    # Business URl\n",
    "    Business_URL = link\n",
    "        ###################################################################################################\n",
    "    Business_Details = [Business_Name,\n",
    "                        Business_Address,\n",
    "                        Business_ReviewCount,\n",
    "                        Business_Rating,\n",
    "                        Business_Photos_Count,\n",
    "                        Business_Timings,\n",
    "                        Business_Claim_status,\n",
    "                        Business_URL\n",
    "                       ]\n",
    "\n",
    "    # Iterating each page of business to get reviews and customer html_tags with Customer Data function\n",
    "    Customer_Data(link, html_tags, Business_Details,Data_Frame, city, category)\n",
    "\n",
    "    return Business_Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "0 https://www.yelp.com/biz/gregs-japanese-auto-seattle?osq=Greg%27s+Japanese+Auto\n",
      "https://www.yelp.com/biz/gregs-japanese-auto-seattle?osq=Greg%27s+Japanese+Auto&start=0\n",
      "https://www.yelp.com/biz/gregs-japanese-auto-seattle?osq=Greg%27s+Japanese+Auto&start=10\n",
      "https://www.yelp.com/biz/gregs-japanese-auto-seattle?osq=Greg%27s+Japanese+Auto&start=20\n",
      "https://www.yelp.com/biz/gregs-japanese-auto-seattle?osq=Greg%27s+Japanese+Auto&start=30\n",
      "https://www.yelp.com/biz/gregs-japanese-auto-seattle?osq=Greg%27s+Japanese+Auto&start=40\n",
      "https://www.yelp.com/biz/gregs-japanese-auto-seattle?osq=Greg%27s+Japanese+Auto&start=50\n",
      "https://www.yelp.com/biz/gregs-japanese-auto-seattle?osq=Greg%27s+Japanese+Auto&start=60\n",
      "https://www.yelp.com/biz/gregs-japanese-auto-seattle?osq=Greg%27s+Japanese+Auto&start=70\n",
      "1 https://www.yelp.com/biz/hng-appliances-tukwila-2?osq=HNG+Appliances\n",
      "https://www.yelp.com/biz/hng-appliances-tukwila-2?osq=HNG+Appliances&start=0\n",
      "https://www.yelp.com/biz/hng-appliances-tukwila-2?osq=HNG+Appliances&start=10\n",
      "https://www.yelp.com/biz/hng-appliances-tukwila-2?osq=HNG+Appliances&start=20\n",
      "https://www.yelp.com/biz/hng-appliances-tukwila-2?osq=HNG+Appliances&start=30\n",
      "https://www.yelp.com/biz/hng-appliances-tukwila-2?osq=HNG+Appliances&start=40\n",
      "https://www.yelp.com/biz/hng-appliances-tukwila-2?osq=HNG+Appliances&start=50\n",
      "https://www.yelp.com/biz/hng-appliances-tukwila-2?osq=HNG+Appliances&start=60\n",
      "https://www.yelp.com/biz/hng-appliances-tukwila-2?osq=HNG+Appliances&start=70\n",
      "2 https://www.yelp.com/biz/plumb-crazy-plumbing-oklahoma-city\n",
      "https://www.yelp.com/biz/plumb-crazy-plumbing-oklahoma-city?start=0\n",
      "https://www.yelp.com/biz/plumb-crazy-plumbing-oklahoma-city?start=10\n",
      "https://www.yelp.com/biz/plumb-crazy-plumbing-oklahoma-city?start=20\n",
      "https://www.yelp.com/biz/plumb-crazy-plumbing-oklahoma-city?start=30\n",
      "https://www.yelp.com/biz/plumb-crazy-plumbing-oklahoma-city?start=40\n",
      "https://www.yelp.com/biz/plumb-crazy-plumbing-oklahoma-city?start=50\n",
      "3 https://www.yelp.com/biz/ca-tire-los-angeles?osq=Tires\n",
      "https://www.yelp.com/biz/ca-tire-los-angeles?osq=Tires&start=0\n",
      "https://www.yelp.com/biz/ca-tire-los-angeles?osq=Tires&start=10\n",
      "https://www.yelp.com/biz/ca-tire-los-angeles?osq=Tires&start=20\n",
      "https://www.yelp.com/biz/ca-tire-los-angeles?osq=Tires&start=30\n",
      "https://www.yelp.com/biz/ca-tire-los-angeles?osq=Tires&start=40\n",
      "https://www.yelp.com/biz/ca-tire-los-angeles?osq=Tires&start=50\n",
      "https://www.yelp.com/biz/ca-tire-los-angeles?osq=Tires&start=60\n",
      "https://www.yelp.com/biz/ca-tire-los-angeles?osq=Tires&start=70\n",
      "https://www.yelp.com/biz/ca-tire-los-angeles?osq=Tires&start=80\n",
      "https://www.yelp.com/biz/ca-tire-los-angeles?osq=Tires&start=90\n",
      "https://www.yelp.com/biz/ca-tire-los-angeles?osq=Tires&start=100\n",
      "https://www.yelp.com/biz/ca-tire-los-angeles?osq=Tires&start=110\n",
      "https://www.yelp.com/biz/ca-tire-los-angeles?osq=Tires&start=120\n",
      "https://www.yelp.com/biz/ca-tire-los-angeles?osq=Tires&start=130\n",
      "https://www.yelp.com/biz/ca-tire-los-angeles?osq=Tires&start=140\n",
      "https://www.yelp.com/biz/ca-tire-los-angeles?osq=Tires&start=150\n",
      "https://www.yelp.com/biz/ca-tire-los-angeles?osq=Tires&start=160\n",
      "https://www.yelp.com/biz/ca-tire-los-angeles?osq=Tires&start=170\n",
      "https://www.yelp.com/biz/ca-tire-los-angeles?osq=Tires&start=180\n",
      "https://www.yelp.com/biz/ca-tire-los-angeles?osq=Tires&start=190\n",
      "https://www.yelp.com/biz/ca-tire-los-angeles?osq=Tires&start=200\n",
      "https://www.yelp.com/biz/ca-tire-los-angeles?osq=Tires&start=210\n",
      "https://www.yelp.com/biz/ca-tire-los-angeles?osq=Tires&start=220\n",
      "https://www.yelp.com/biz/ca-tire-los-angeles?osq=Tires&start=230\n",
      "https://www.yelp.com/biz/ca-tire-los-angeles?osq=Tires&start=240\n",
      "https://www.yelp.com/biz/ca-tire-los-angeles?osq=Tires&start=250\n",
      "4 https://www.yelp.com/biz/davids-auto-repair-brooklyn?osq=Auto+Repair\n",
      "https://www.yelp.com/biz/davids-auto-repair-brooklyn?osq=Auto+Repair&start=0\n",
      "https://www.yelp.com/biz/davids-auto-repair-brooklyn?osq=Auto+Repair&start=10\n",
      "https://www.yelp.com/biz/davids-auto-repair-brooklyn?osq=Auto+Repair&start=20\n",
      "https://www.yelp.com/biz/davids-auto-repair-brooklyn?osq=Auto+Repair&start=30\n",
      "https://www.yelp.com/biz/davids-auto-repair-brooklyn?osq=Auto+Repair&start=40\n",
      "https://www.yelp.com/biz/davids-auto-repair-brooklyn?osq=Auto+Repair&start=50\n",
      "https://www.yelp.com/biz/davids-auto-repair-brooklyn?osq=Auto+Repair&start=60\n",
      "https://www.yelp.com/biz/davids-auto-repair-brooklyn?osq=Auto+Repair&start=70\n",
      "5 https://www.yelp.com/biz/212-painter-new-york-2?osq=Painters\n",
      "https://www.yelp.com/biz/212-painter-new-york-2?osq=Painters&start=0\n",
      "https://www.yelp.com/biz/212-painter-new-york-2?osq=Painters&start=10\n",
      "https://www.yelp.com/biz/212-painter-new-york-2?osq=Painters&start=20\n",
      "https://www.yelp.com/biz/212-painter-new-york-2?osq=Painters&start=30\n",
      "https://www.yelp.com/biz/212-painter-new-york-2?osq=Painters&start=40\n",
      "https://www.yelp.com/biz/212-painter-new-york-2?osq=Painters&start=50\n",
      "https://www.yelp.com/biz/212-painter-new-york-2?osq=Painters&start=60\n",
      "https://www.yelp.com/biz/212-painter-new-york-2?osq=Painters&start=70\n",
      "https://www.yelp.com/biz/212-painter-new-york-2?osq=Painters&start=80\n",
      "6 https://www.yelp.com/biz/america-refinishing-pros-miami-2?osq=Flooring\n",
      "https://www.yelp.com/biz/america-refinishing-pros-miami-2?osq=Flooring&start=0\n",
      "https://www.yelp.com/biz/america-refinishing-pros-miami-2?osq=Flooring&start=10\n",
      "https://www.yelp.com/biz/america-refinishing-pros-miami-2?osq=Flooring&start=20\n",
      "https://www.yelp.com/biz/america-refinishing-pros-miami-2?osq=Flooring&start=30\n",
      "7 https://www.yelp.com/biz/beyond-handyman-services-pompano-beach?osq=Handyman\n",
      "https://www.yelp.com/biz/beyond-handyman-services-pompano-beach?osq=Handyman&start=0\n",
      "https://www.yelp.com/biz/beyond-handyman-services-pompano-beach?osq=Handyman&start=10\n"
     ]
    }
   ],
   "source": [
    "if __name__== '__main__':\n",
    "    \n",
    "    # Loading the HTML tags from Data json file\n",
    "    with open('../Data_HTML_Tags/html_tags.json') as f:\n",
    "        html_tags = json.load(f)\n",
    "        \n",
    "    #####################################Input Data#############################################   \n",
    "    # Reading the input data city and category from json file\n",
    "    with open('../Data_HTML_Tags/Input.json') as f:\n",
    "        Input_data = json.load(f)\n",
    "    \n",
    "    city = Input_data['city']\n",
    "    category = Input_data['category']\n",
    "    \n",
    "    # Reading the business links from the CSV and storing into list\n",
    "    df = pd.read_csv('../Data_Business_URL_Links/Business_links_{0}_{1}.csv'.format(category, city))    \n",
    "    Business_links = df['Business_links']\n",
    "    print(len(Business_links))\n",
    "    Business_links = Business_links.tolist()\n",
    "\n",
    "    # creating  a Data frame to save data\n",
    "    Data_Frame =pd.DataFrame(columns= [ 'Business_Name', 'Business_Address', 'Business_ReviewCount', 'Business_Rating',\n",
    "                                        'Business_Photos_Count', 'Business_Timings', 'Business_Claim_status', 'Business_URL',\n",
    "                                       'Customer_Name','Customer_Friends_count', 'Customer_Reviews_count', 'Customer_Photos_count', 'Customer_Elite',\n",
    "                                        'Customer_Elite_Year', 'Customer_Rating', 'Customer_Review', 'Customer_Review_Date', \n",
    "                                        'Customer_Review_Uploaded_Photos', 'Customer_Review_Useful', 'Customer_Review_Funny', \n",
    "                                        'Customer_Review_Cool', 'Business_response_By', 'Business_response_Date', \n",
    "                                        'Business_Response_for_Review', 'Business_Response']) \n",
    "    \n",
    "    # Creating a CSV file with headers to save data\n",
    "    Data_Frame.to_csv('../Data_Business_Reviews/Yelp_Business_Reviews_{0}_{1}.csv'.format(city, category), header=True)\n",
    "    \n",
    "    # iterating through each url to extract the business Reviews data\n",
    "    for i in range(0,len(Business_links),1):       \n",
    "        try:\n",
    "            link = Business_links[i]      \n",
    "            driver = webdriver.Chrome('../chromedriver/chromedriver.exe')\n",
    "            driver.get(link)\n",
    "            \n",
    "            # this is just to ensure that the page is loaded\n",
    "            time.sleep(2)\n",
    "            html = driver.page_source\n",
    "            driver.quit()\n",
    "            # Now, we could simply apply bs4 to html variable\n",
    "            soup = BeautifulSoup(html, \"html.parser\")\n",
    "            \n",
    "            # ckecking the the business has reviews or not\n",
    "            Business_class = soup.find('div', class_=html_tags['B_class'])              \n",
    "            Reviwes_check = soup.find_all('div', class_=html_tags['Reviews_Div'])\n",
    "            \n",
    "            if Reviwes_check:\n",
    "                print(i, link) \n",
    "                # after validating the business has reviews call the function to extract the data\n",
    "                Business_Data(soup, html_tags, link, Data_Frame, city, category)\n",
    "            else:\n",
    "                print('No Reviews')\n",
    "                print(i, link) \n",
    "          \n",
    "        \n",
    "        except:            \n",
    "            pass\n",
    "\n",
    "        \n",
    "\n",
    " \n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
