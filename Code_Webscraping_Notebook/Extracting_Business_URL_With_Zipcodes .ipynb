{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\prudhvi\\anaconda3\\lib\\site-packages (3.141.0)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\prudhvi\\anaconda3\\lib\\site-packages (from selenium) (1.26.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium\n",
    "import pandas as pd\n",
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from urllib.parse import urlparse\n",
    "import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a list of url's where each url in the list is yelp page url for combination of zipcode and category\n",
    "def Extracting_Yelp_Main_URl_By_Zipcodes(category, zipcodes):\n",
    "    zipcode_URL = []\n",
    "    for zipcode in zipcodes:\n",
    "        zipcode_URL.append('https://www.yelp.com/search?find_desc={0}&find_loc={1}&start=0'.format(category,zipcode))\n",
    "    return zipcode_URL\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract the URL of pages which has the business links\n",
    "def Extracting_URL(main_url, links):\n",
    "    \n",
    "    # initiating the webdriver. Parameter includes the path of the webdriver.\n",
    "    driver = webdriver.Chrome('../chromedriver/chromedriver.exe')\n",
    "    driver.get(main_url)\n",
    "    # this is just to ensure that the page is loaded\n",
    "#     time.sleep(3)\n",
    "    html = driver.page_source\n",
    "    driver.quit()\n",
    "    \n",
    "    # Now, we apply beautiful soup to html variable\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    # finding all tags in the soup\n",
    "    tags = soup('a', href=True)\n",
    "    # checking each tag and appending to the links list if it is valid\n",
    "    for tag in tags:\n",
    "        if \"start\" in tag[\"href\"]:\n",
    "            if ('www.yelp.com/search?find_desc=' in tag['href'] ) and (tag['href'] not in links) and ('login' not in tag['href']) and ('signup'not in tag['href'])and ('biz' not in tag['href']):\n",
    "                links.append(tag['href'])\n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to extract the Business URl from the page\n",
    "\n",
    "def Extracting_Business_URL(main_url, base_url, Business_links):\n",
    "\n",
    "    # initiating the webdriver. Parameter includes the path of the webdriver.\n",
    "    driver = webdriver.Chrome('../chromedriver/chromedriver.exe')\n",
    "    driver.get(main_url)\n",
    "    # this is just to ensure that the page is loaded\n",
    "#     time.sleep(3)\n",
    "    html = driver.page_source\n",
    "    driver.quit()\n",
    "    \n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    tags = soup.find_all(\"a\", class_=\"css-166la90\")\n",
    "    \n",
    "    # checking each tag and if it is a business tag appending to the Business list if it is valid\n",
    "    for tag in tags:\n",
    "        if (\"osq\" in tag[\"href\"]) :\n",
    "            Business_links.append(base_url + tag['href'])\n",
    "\n",
    "    return Business_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the main function accepts the below params\n",
    "#  base_url : yelp url \n",
    "#  main_url : url obtained from category and zipcode combination\n",
    "#  counter  : counter to know count of present url\n",
    "#  city     : selected city\n",
    "#  category : selected category\n",
    "\n",
    "\n",
    "def main(base_url,main_url,current_zipcode, city, category):\n",
    "    \n",
    "    # list to store the url of pages with business list\n",
    "    links = []\n",
    "    \n",
    "    # list to store the list of business url\n",
    "    Business_links = []\n",
    "    \n",
    "    # Extracting all page urls with business list\n",
    "    for i in range(1, 6):       \n",
    "        #calling the function to extract the url pages with business url\n",
    "        links = Extracting_URL(main_url, links)       \n",
    "        # setting the last url of the list from the result of above function as main_url\n",
    "        main_url = links[-1]\n",
    "                 \n",
    "    for link in links:\n",
    "        #calling the function to extract the business url from the function\n",
    "        Business_links=Extracting_Business_URL(link, base_url, Business_links)\n",
    "        \n",
    "    # Saving all the Business URL to csv file\n",
    "    df = pd.DataFrame({'Business_links': Business_links})\n",
    "    df.to_csv('../Data_Business_URL_City_and_Category_Wise/{0}/{1}/Business_links_{2}.csv'.format(city, category, current_zipcode))\n",
    "    \n",
    "    print(len(Business_links))\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting time: time.struct_time(tm_year=2021, tm_mon=4, tm_mday=5, tm_hour=0, tm_min=50, tm_sec=37, tm_wday=0, tm_yday=95, tm_isdst=1)\n",
      "0 https://www.yelp.com/search?find_desc=Plumbing&find_loc=98101&start=0\n",
      "228\n",
      "1 https://www.yelp.com/search?find_desc=Plumbing&find_loc=98102&start=0\n",
      "228\n",
      "2 https://www.yelp.com/search?find_desc=Plumbing&find_loc=98103&start=0\n",
      "229\n",
      "3 https://www.yelp.com/search?find_desc=Plumbing&find_loc=98104&start=0\n",
      "229\n",
      "4 https://www.yelp.com/search?find_desc=Plumbing&find_loc=98105&start=0\n",
      "229\n",
      "5 https://www.yelp.com/search?find_desc=Plumbing&find_loc=98106&start=0\n",
      "228\n",
      "6 https://www.yelp.com/search?find_desc=Plumbing&find_loc=98107&start=0\n",
      "229\n",
      "7 https://www.yelp.com/search?find_desc=Plumbing&find_loc=98108&start=0\n",
      "228\n",
      "8 https://www.yelp.com/search?find_desc=Plumbing&find_loc=98109&start=0\n",
      "229\n",
      "9 https://www.yelp.com/search?find_desc=Plumbing&find_loc=98111&start=0\n",
      "229\n",
      "10 https://www.yelp.com/search?find_desc=Plumbing&find_loc=98112&start=0\n",
      "230\n",
      "11 https://www.yelp.com/search?find_desc=Plumbing&find_loc=98113&start=0\n",
      "230\n",
      "12 https://www.yelp.com/search?find_desc=Plumbing&find_loc=98114&start=0\n",
      "229\n",
      "13 https://www.yelp.com/search?find_desc=Plumbing&find_loc=98115&start=0\n",
      "199\n",
      "14 https://www.yelp.com/search?find_desc=Plumbing&find_loc=98116&start=0\n",
      "228\n",
      "15 https://www.yelp.com/search?find_desc=Plumbing&find_loc=98117&start=0\n",
      "229\n",
      "16 https://www.yelp.com/search?find_desc=Plumbing&find_loc=98118&start=0\n",
      "230\n",
      "17 https://www.yelp.com/search?find_desc=Plumbing&find_loc=98119&start=0\n",
      "229\n",
      "18 https://www.yelp.com/search?find_desc=Plumbing&find_loc=98121&start=0\n",
      "230\n",
      "19 https://www.yelp.com/search?find_desc=Plumbing&find_loc=98122&start=0\n",
      "228\n",
      "20 https://www.yelp.com/search?find_desc=Plumbing&find_loc=98124&start=0\n",
      "230\n",
      "21 https://www.yelp.com/search?find_desc=Plumbing&find_loc=98125&start=0\n",
      "228\n",
      "22 https://www.yelp.com/search?find_desc=Plumbing&find_loc=98126&start=0\n",
      "229\n",
      "23 https://www.yelp.com/search?find_desc=Plumbing&find_loc=98127&start=0\n",
      "230\n",
      "24 https://www.yelp.com/search?find_desc=Plumbing&find_loc=98129&start=0\n",
      "175\n",
      "25 https://www.yelp.com/search?find_desc=Plumbing&find_loc=98131&start=0\n",
      "174\n",
      "26 https://www.yelp.com/search?find_desc=Plumbing&find_loc=98133&start=0\n",
      "229\n",
      "27 https://www.yelp.com/search?find_desc=Plumbing&find_loc=98134&start=0\n",
      "229\n",
      "28 https://www.yelp.com/search?find_desc=Plumbing&find_loc=98136&start=0\n",
      "229\n",
      "29 https://www.yelp.com/search?find_desc=Plumbing&find_loc=98138&start=0\n",
      "229\n",
      "30 https://www.yelp.com/search?find_desc=Plumbing&find_loc=98139&start=0\n",
      "229\n",
      "31 https://www.yelp.com/search?find_desc=Plumbing&find_loc=98141&start=0\n",
      "228\n",
      "32 https://www.yelp.com/search?find_desc=Plumbing&find_loc=98144&start=0\n",
      "230\n",
      "33 https://www.yelp.com/search?find_desc=Plumbing&find_loc=98145&start=0\n",
      "116\n",
      "34 https://www.yelp.com/search?find_desc=Plumbing&find_loc=98146&start=0\n",
      "226\n",
      "35 https://www.yelp.com/search?find_desc=Plumbing&find_loc=98148&start=0\n",
      "228\n",
      "36 https://www.yelp.com/search?find_desc=Plumbing&find_loc=98154&start=0\n",
      "228\n",
      "37 https://www.yelp.com/search?find_desc=Plumbing&find_loc=98155&start=0\n",
      "230\n",
      "38 https://www.yelp.com/search?find_desc=Plumbing&find_loc=98158&start=0\n",
      "failed URL\n",
      "38 https://www.yelp.com/search?find_desc=Plumbing&find_loc=98158&start=0\n",
      "39 https://www.yelp.com/search?find_desc=Plumbing&find_loc=98160&start=0\n",
      "229\n",
      "40 https://www.yelp.com/search?find_desc=Plumbing&find_loc=98161&start=0\n",
      "228\n",
      "41 https://www.yelp.com/search?find_desc=Plumbing&find_loc=98164&start=0\n",
      "217\n",
      "42 https://www.yelp.com/search?find_desc=Plumbing&find_loc=98165&start=0\n",
      "229\n",
      "43 https://www.yelp.com/search?find_desc=Plumbing&find_loc=98166&start=0\n",
      "229\n",
      "44 https://www.yelp.com/search?find_desc=Plumbing&find_loc=98168&start=0\n",
      "228\n",
      "45 https://www.yelp.com/search?find_desc=Plumbing&find_loc=98170&start=0\n",
      "229\n",
      "46 https://www.yelp.com/search?find_desc=Plumbing&find_loc=98174&start=0\n",
      "229\n",
      "47 https://www.yelp.com/search?find_desc=Plumbing&find_loc=98175&start=0\n",
      "229\n",
      "48 https://www.yelp.com/search?find_desc=Plumbing&find_loc=98177&start=0\n",
      "229\n",
      "49 https://www.yelp.com/search?find_desc=Plumbing&find_loc=98178&start=0\n",
      "228\n",
      "50 https://www.yelp.com/search?find_desc=Plumbing&find_loc=98181&start=0\n",
      "230\n",
      "51 https://www.yelp.com/search?find_desc=Plumbing&find_loc=98185&start=0\n",
      "228\n",
      "52 https://www.yelp.com/search?find_desc=Plumbing&find_loc=98188&start=0\n",
      "229\n",
      "53 https://www.yelp.com/search?find_desc=Plumbing&find_loc=98190&start=0\n",
      "229\n",
      "54 https://www.yelp.com/search?find_desc=Plumbing&find_loc=98191&start=0\n",
      "228\n",
      "55 https://www.yelp.com/search?find_desc=Plumbing&find_loc=98194&start=0\n",
      "229\n",
      "56 https://www.yelp.com/search?find_desc=Plumbing&find_loc=98195&start=0\n",
      "114\n",
      "57 https://www.yelp.com/search?find_desc=Plumbing&find_loc=98198&start=0\n",
      "228\n",
      "58 https://www.yelp.com/search?find_desc=Plumbing&find_loc=98199&start=0\n",
      "228\n"
     ]
    }
   ],
   "source": [
    "if __name__== '__main__':\n",
    "    \n",
    "    # Loading the Zipcodes from the json file\n",
    "    # Zipcode_data is a dictonary object with 'key'=city name and 'values' = zipcodes for city \n",
    "    with open('../Data_HTML_Tags/zipcodes.json') as f:\n",
    "        zipcode_data = json.load(f)\n",
    "     \n",
    "    #####################################Input Data#############################################   \n",
    "    # Reading the input data city and category from json file\n",
    "    with open('../Data_HTML_Tags/Input.json') as f:\n",
    "        Input_data = json.load(f)\n",
    "    \n",
    "    city = Input_data['city']\n",
    "    category = Input_data['category']\n",
    "    \n",
    "    zipcodes = zipcode_data[city]\n",
    "    \n",
    "    print(\"starting time:\", time.localtime(time.time()))\n",
    "    zipcode_URL = Extracting_Yelp_Main_URl_By_Zipcodes(category, zipcodes)\n",
    "#     print(len(zipcode_URL))\n",
    "    \n",
    "    for i in range(0,len(zipcode_URL),1):\n",
    "        try:\n",
    "            # base URl is the main yelp URL\n",
    "            base_url = 'https://www.yelp.com'\n",
    "            \n",
    "            # main_url is the intial search page url with results based on category and zipcode\n",
    "            main_url = zipcode_URL[i]\n",
    "            current_Zipcode = zipcodes[i]\n",
    "            \n",
    "            # parsing the url to make sure the url is correct\n",
    "            parse = urlparse(main_url)\n",
    "            main_url= parse.geturl()\n",
    "            print(i,main_url)\n",
    "                \n",
    "            # calling the main function\n",
    "            main(base_url, main_url, current_Zipcode, city, category) \n",
    "        \n",
    "#         break\n",
    "        except:\n",
    "            print('failed URL')\n",
    "            print(i,main_url)\n",
    "            pass\n",
    "\n",
    "\n",
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of Data frame with Duplicate URL : 12892\n",
      "The length of DataFrame after droping the Duplicates : 662\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def Remove_Duplicates(DataFrame, path, city, category):\n",
    "    for fname in glob.glob(path):\n",
    "        df = pd.read_csv(fname)\n",
    "        DataFrame = DataFrame.append(df, ignore_index=True)\n",
    "\n",
    "    # Dropping the Duplicate values:\n",
    "    print(\"The length of Data frame with Duplicate URL :\",len(DataFrame))\n",
    "    DataFrame = DataFrame.drop_duplicates(subset=\"Business_links\")\n",
    "    print('The length of DataFrame after droping the Duplicates :', len(DataFrame))\n",
    "\n",
    "    DataFrame.to_csv('../Data_Business_URL_Links/Business_links_{0}_{1}.csv'.format(category, city))\n",
    "\n",
    "    return 0\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    #####################################Input Data#############################################   \n",
    "    # Reading the input data city and category from json file\n",
    "    with open('../Data_HTML_Tags/Input.json') as f:\n",
    "        Input_data = json.load(f)\n",
    "    \n",
    "    city = Input_data['city']\n",
    "    category = Input_data['category']\n",
    "    \n",
    "    \n",
    "    DataFrame = pd.DataFrame()\n",
    "    path = '../Data_Business_URL_City_and_Category_Wise/{0}/{1}/Business_links_*.csv'.format(city,category)\n",
    "\n",
    "    Remove_Duplicates(DataFrame, path, city, category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
